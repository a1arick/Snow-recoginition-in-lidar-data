{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e69feef",
   "metadata": {},
   "source": [
    "# В этой тетрадке мы разобъем все три датасета на train и test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bb47a503",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21578cd4",
   "metadata": {},
   "source": [
    "230 -- количество сцен в наших данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86deb2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "scenes = np.linspace(0, 229, num=230).astype(int)\n",
    "np.random.shuffle(scenes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cbb2e51d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167,  92,  57,  15,  62, 185,  32, 195, 222, 173,  83,  65,  36,\n",
       "       194, 150,  11,  49,  33,  88,  63,  24, 122, 212,  21,  43, 206,\n",
       "       182,  18, 130, 153, 197, 229,  69,  96, 157,  37, 217, 132, 100,\n",
       "       117,  10,  71, 175,  45,  85,  51, 221, 228, 124,  31,  30,   1,\n",
       "        55, 116, 204, 196, 125, 187,  47, 148, 215, 193, 203,   8, 142,\n",
       "       209,  80,  68, 166, 165,  79,  61, 149,  54,  90, 176,  70, 115,\n",
       "       208, 163,  46,  78, 107, 213, 138, 216,  66, 168,  75, 155,  53,\n",
       "       158, 178, 152, 136, 135,  58, 161, 207,  87,  98, 218, 192, 120,\n",
       "        91, 170, 199, 113,  59, 109, 179,  40, 108,  86, 202,  44,  13,\n",
       "       118,  94,   0, 139,   6, 226, 225, 159,  27,  48, 174, 191, 143,\n",
       "       140, 189, 146,  26, 183, 141, 169,  64,  29,   5, 172,  19, 129,\n",
       "       137, 144, 131, 180, 114, 210,  81, 190, 147,  84,  82, 112, 110,\n",
       "         3,  17,  39, 181, 126,  35, 111, 223, 201, 121, 123,  60, 133,\n",
       "        99,   7,  14, 162,  34, 106, 198, 101,   9, 227,   2,  56,  97,\n",
       "       211, 134, 171,  28, 127,  25, 160, 105,  76, 184,  77,  93, 186,\n",
       "        95, 102, 103,  50, 177,  16,  72,   4, 128, 188, 219,  20, 156,\n",
       "        12, 119,  22,  89, 164,  73,  74, 154, 151,  38,  42,  67,  23,\n",
       "       104,  41, 205, 214, 145, 200,  52, 224, 220])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scenes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b2eeb68",
   "metadata": {},
   "source": [
    "возьмем 80% всех сцен в train и 20% в test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3dab240",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size = int(0.8 * 230)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cc8d70c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_scene_id = scenes[0 : train_size]\n",
    "test_scene_id = scenes[train_size : ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3baf74ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([167,  92,  57,  15,  62, 185,  32, 195, 222, 173,  83,  65,  36,\n",
       "       194, 150,  11,  49,  33,  88,  63,  24, 122, 212,  21,  43, 206,\n",
       "       182,  18, 130, 153, 197, 229,  69,  96, 157,  37, 217, 132, 100,\n",
       "       117,  10,  71, 175,  45,  85,  51, 221, 228, 124,  31,  30,   1,\n",
       "        55, 116, 204, 196, 125, 187,  47, 148, 215, 193, 203,   8, 142,\n",
       "       209,  80,  68, 166, 165,  79,  61, 149,  54,  90, 176,  70, 115,\n",
       "       208, 163,  46,  78, 107, 213, 138, 216,  66, 168,  75, 155,  53,\n",
       "       158, 178, 152, 136, 135,  58, 161, 207,  87,  98, 218, 192, 120,\n",
       "        91, 170, 199, 113,  59, 109, 179,  40, 108,  86, 202,  44,  13,\n",
       "       118,  94,   0, 139,   6, 226, 225, 159,  27,  48, 174, 191, 143,\n",
       "       140, 189, 146,  26, 183, 141, 169,  64,  29,   5, 172,  19, 129,\n",
       "       137, 144, 131, 180, 114, 210,  81, 190, 147,  84,  82, 112, 110,\n",
       "         3,  17,  39, 181, 126,  35, 111, 223, 201, 121, 123,  60, 133,\n",
       "        99,   7,  14, 162,  34, 106, 198, 101,   9, 227,   2,  56,  97,\n",
       "       211, 134])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_scene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "754c6dc5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([171,  28, 127,  25, 160, 105,  76, 184,  77,  93, 186,  95, 102,\n",
       "       103,  50, 177,  16,  72,   4, 128, 188, 219,  20, 156,  12, 119,\n",
       "        22,  89, 164,  73,  74, 154, 151,  38,  42,  67,  23, 104,  41,\n",
       "       205, 214, 145, 200,  52, 224, 220])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_scene_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0ac6b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"/Volumes/HP P800/itmo/Lidar data/data.csv\")\n",
    "\n",
    "df_train = df[df['scene_id'].isin(train_scene_id)]\n",
    "df_test = df[df['scene_id'].isin(test_scene_id)]\n",
    "\n",
    "df_train.to_csv(\"/Volumes/HP P800/itmo/Lidar data/data_train.csv\")\n",
    "df_test.to_csv(\"/Volumes/HP P800/itmo/Lidar data/data_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc66040",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.read_csv(\"/Volumes/HP P800/itmo/Lidar data/data_simple_preprocess_normalize_all_columns.csv\", index_col=0)\n",
    "\n",
    "df_1_train = df_1[df_1['scene_id'].isin(train_scene_id)]\n",
    "df_1_test = df_1[df_1['scene_id'].isin(test_scene_id)]\n",
    "\n",
    "df_1_train.to_csv(\"/Volumes/HP P800/itmo/Lidar data/data_simple_preprocess_normalize_all_columns_train.csv\")\n",
    "df_1_test.to_csv(\"/Volumes/HP P800/itmo/Lidar data/data_simple_preprocess_normalize_all_columns_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "236179c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kdtree = pd.read_csv(\"/Volumes/HP P800/itmo/Lidar data/data_kdtree_preprocess.csv\", index_col=0)\n",
    "\n",
    "df_kdtree_train = df_kdtree[df_kdtree['scene_id'].isin(train_scene_id)]\n",
    "df_kdtree_test = df_kdtree[df_kdtree['scene_id'].isin(test_scene_id)]\n",
    "\n",
    "df_kdtree_train.to_csv(\"/Volumes/HP P800/itmo/Lidar data/df_kdtree_train.csv\")\n",
    "df_kdtree_test.to_csv(\"/Volumes/HP P800/itmo/Lidar data/df_kdtree_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4b7aff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
